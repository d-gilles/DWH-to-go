{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a test dataset \n",
    ".. and put it into our datalake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import io\n",
    "\n",
    "# load .env\n",
    "load_dotenv()\n",
    "\n",
    "# set variables\n",
    "os.environ[\"AWS_CONFIG_FILE\"] = \"~/.aws/config_terraform\"\n",
    "os.environ[\"AWS_SHARED_CREDENTIALS_FILE\"] = \"~/.aws/cred_terraform\"\n",
    "aws_region = os.getenv('AWS_REGION')\n",
    "aws_profile = os.getenv('AWS_TERRAFORM_USER')\n",
    "PROJECT_NAME=os.getenv('PROJECT_NAME')\n",
    "ITERATION=os.getenv('ITERATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create boto3 session\n",
    "aws_session = boto3.Session(profile_name=aws_profile)\n",
    "s3_client = aws_session.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/static/public/352/online+retail.zip'\n",
    "folder_path = 'data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordner 'data' wurde gelöscht.\n",
      "Ordner 'data' wurde erstellt.\n"
     ]
    }
   ],
   "source": [
    "# create empty folder\n",
    "if os.path.exists(folder_path):\n",
    "    shutil.rmtree(folder_path)\n",
    "    print(f\"Ordner '{folder_path}' wurde gelöscht.\")\n",
    "else:\n",
    "    print(f\"Ordner '{folder_path}' existiert nicht.\")\n",
    "os.makedirs(folder_path)\n",
    "print(f\"Ordner '{folder_path}' wurde erstellt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "wget.download(url, 'data.zip')\n",
    "with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(path=folder_path)\n",
    "os.remove('data.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the xlsx file\n",
    "file = os.listdir(folder_path)[0]\n",
    "df = pd.read_excel(os.path.join(folder_path, file))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541909, 8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo              object\n",
       "StockCode              object\n",
       "Description            object\n",
       "Quantity                int64\n",
       "InvoiceDate    datetime64[ns]\n",
       "UnitPrice             float64\n",
       "CustomerID            float64\n",
       "Country                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "df_1 = df[df['InvoiceNo'].astype(str).str.isdigit()]\n",
    "df_1.loc[:,'StockCode'] = df_1['StockCode'].fillna(\"\").astype(str)\n",
    "df_1.loc[:,'Description'] = df_1['Description'].fillna(\"\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(532618, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write file as parquet\n",
    "new_file_name = f\"{file.split('.')[0].replace(' ', '')}.parquet\"\n",
    "df_1.to_parquet(os.path.join(folder_path, new_file_name), engine=\"pyarrow\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = pd.read_parquet(os.path.join(folder_path, new_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to s3://lenico-dwh-i1-data-lake/staging/OnlineRetail.parquet\n"
     ]
    }
   ],
   "source": [
    "# upload parquet file to s3\n",
    "bucket = f\"{PROJECT_NAME}-i{ITERATION}-data-lake\"\n",
    "key = f\"staging/{new_file_name}\"\n",
    "\n",
    "\n",
    "# DataFrame in einen Bytes-Buffer als Parquet schreiben\n",
    "buffer = io.BytesIO()\n",
    "df_1.to_parquet(buffer, engine='pyarrow', index=False)\n",
    "\n",
    "\n",
    "# Upload\n",
    "s3_client.put_object(Bucket=bucket, Key=key, Body=buffer.getvalue())\n",
    "\n",
    "print(f\"File uploaded to s3://{bucket}/{key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InvoiceNo              object\n",
       "StockCode              object\n",
       "Description            object\n",
       "Quantity                int64\n",
       "InvoiceDate    datetime64[ns]\n",
       "UnitPrice             float64\n",
       "CustomerID            float64\n",
       "Country                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_1.dtypes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df[df['InvoiceDate'] > pd.Timestamp.now()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-12-09 12:50:00\n"
     ]
    }
   ],
   "source": [
    "print(df['InvoiceDate'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InvoiceDate'] = df['InvoiceDate'].astype('string')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Prüfen Sie, ob es Werte mit mehr als 13 Stellen gibt (Nanosekunden):\n",
    "invalid_timestamps = df[df['InvoiceDate'] > pd.Timestamp('3000-01-01')]\n",
    "print(invalid_timestamps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-sf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
